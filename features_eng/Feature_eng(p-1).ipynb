{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset making  \n",
    "this notebook contains the code for making the dataset \n",
    "\n",
    "### table of content \n",
    "\n",
    "\n",
    "1. [Date format change](#date-format-change)\n",
    "2. [Sector volume](#Sector-volume)\n",
    "3. [A_category volume](#A_category-volume)\n",
    "4. [Desx,Ds30 ,Dsex calculation](#desx-ds30-dsex-calculation)\n",
    "5. [Desx,Ds30 ,Dsex value change](#desx-ds30-dsex-value-change)\n",
    "6. [Ranking by sector volume](#ranking-by-sector-volume)\n",
    "7. [Gold rate (Global)](#Gold-rate-global)\n",
    "8. [Foren exchange buying and selling rate](#foren-exchange-buying-and-selling-rate    )\n",
    "9. [BD reserve](#bd-reserve)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perameter setting\n",
    "[back to top](#table-of-content)\n",
    "\n",
    "```python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_data_dir = r'C:\\Users\\Amzad\\Desktop\\stock_prediction\\data\\daily_data'\n",
    "data_dir = r'C:\\Users\\Amzad\\Desktop\\stock_prediction\\data'\n",
    "new_data_dir = r'C:\\Users\\Amzad\\Desktop\\stock_prediction\\data\\export.csv'\n",
    "gold_csv_dir =r'C:\\Users\\Amzad\\Desktop\\stock_prediction\\data\\gold.csv'\n",
    "latest_data_dir = r'C:\\Users\\Amzad\\Desktop\\stock_prediction\\datadataset_v4_df.csv'\n",
    "daily_data = os.listdir(daily_data_dir)\n",
    "A_cat_comapny = []\n",
    "pharma_comapny = []\n",
    "\n",
    "All_present_company = ['Code', '1JANATAMF', 'PTL', '1STPRIMFMF', 'ABBANK', 'ACI', 'ACIFORMULA', 'ACTIVEFINE', 'AFTABAUTO', 'AGNISYSL', 'AGRANINS', 'AIBL1STIMF', 'ALARABANK', 'AL-HAJTEX', 'ALLTEX', 'AMBEEPHA', 'AMCL(PRAN)', 'ANLIMAYARN', 'ANWARGALV', 'APEXFOOT', 'APEXFOODS', 'APEXSPINN', 'BEACHHATCH', 'BEACONPHAR', 'BARKAPOWER', 'BERGERPBL', 'BEXIMCO', 'BGIC', 'BIFC', 'APEXTANRY', 'ARAMIT', 'ARAMITCEM', 'ASIAINS', 'ASIAPACINS', 'ATLASBANG', 'AZIZPIPES', 'BANGAS', 'BANKASIA', 'LINDEBD', 'BRACBANK', 'BSC', 'BSRMSTEEL', 'BXPHARMA', 'CENTRALINS', 'CITYBANK', 'CITYGENINS', 'ALIF', 'CONFIDCEM', 'BATASHOE', 'BATBC', 'BDAUTOCA', 'BDCOM', 'BDFINANCE', 'BDLAMPS', 'BDTHAI', 'BDWELDING', 'CONTININS', 'CVOPRL', 'DACCADYE', 'DAFODILCOM', 'DBH', 'DBH1STMF', 'DELTALIFE', 'DELTASPINN', 'DESCO', 'DESHBANDHU', 'DHAKABANK', 'DHAKAINS', 'DSHGARME', 'DULAMIACOT', 'DUTCHBANGL', 'EASTERNINS', 'EASTLAND', 'EASTRNLUB', 'EBL', 'EBL1STMF', 'EBLNRBMF', 'ECABLES', 'EHL', 'EXIMBANK', 'FAREASTLIF', 'FASFIN', 'FEDERALINS', 'FINEFOODS', 'FIRSTSBANK', 'FIRSTFIN', 'FUWANGFOOD', 'GEMINISEA', 'GLOBALINS', 'GOLDENSON', 'GP', 'GQBALLPEN', 'GRAMEENS2', 'GREENDELMF', 'GREENDELT', 'HAKKANIPUL', 'HEIDELBCEM', 'HRTEX', 'IBNSINA', 'ICB', 'ICB3RDNRB', 'BBS', 'LIBRAINFU', 'MAKSONSPIN', 'MALEKSPIN', 'MARICO', 'MBL1STMF', 'MEGCONMILK', 'MEGHNACEM', 'MEGHNALIFE', 'MEGHNAPET', 'MERCANBANK', 'MERCINS', 'METROSPIN', 'MIDASFIN', 'MIRACLEIND', 'MONNOCERA', 'RDFOOD', 'MPETROLEUM', 'MTB', 'NATLIFEINS', 'NAVANACNG', 'NBL', 'ICBAMCL2ND', 'ICBIBANK', 'IDLC', 'IFIC', 'IFIC1STMF', 'IFILISLMF1', 'ILFSL', 'IMAMBUTTON', 'INTECH', 'IPDC', 'ISLAMIBANK', 'ISLAMICFIN', 'ISLAMIINS', 'ISNLTD', 'JAMUNABANK', 'JAMUNAOIL', 'JANATAINS', 'JUTESPINN', 'KARNAPHULI', 'KAY&QUE', 'KEYACOSMET', 'KOHINOOR', 'KPCL', 'LHBL', 'LANKABAFIN', 'LEGACYFOOT', 'NCCBANK', 'NHFIL', 'NITOLINS', 'NORTHERN', 'PRAGATIINS', 'PRAGATILIF', 'PREMIERBAN', 'PREMIERLEA', 'PRIME1ICBA', 'PRIMEBANK', 'PRIMEFIN', 'PRIMELIFE', 'PRIMETEX', 'PROGRESLIF', 'NORTHRNINS', 'NPOLYMER', 'NTC', 'NTLTUBES', 'SUNLIFEINS', 'OLYMPIC', 'ONEBANKLTD', 'ORIONINFU', 'PADMAOIL', 'PARAMOUNT', 'PEOPLESINS', 'PF1STMF', 'PHARMAID', 'PHENIXINS', 'PHOENIXFIN', 'PHPMF1', 'PIONEERINS', 'POPULAR1MF', 'POPULARLIF', 'POWERGRID', 'PROVATIINS', 'PUBALIBANK', 'PURABIGEN', 'QUASEMIND', 'RAHIMTEXT', 'RAKCERAMIC', 'RANFOUNDRY', 'RECKITTBEN', 'RELIANCINS', 'RENATA', 'RENWICKJA', 'REPUBLIC',\n",
    "                       'RNSPIN', 'RUPALIBANK', 'RUPALIINS', 'RUPALILIFE', 'ZEALBANGLA', 'UTTARABANK', 'USMANIAGL', 'UNITEDINS', 'UNIONCAP', 'UNITEDFIN', 'UCB', 'TRUSTBANK', 'TRUSTB1MF', 'TITASGAS', 'TALLUSPIN', 'TAKAFULINS', 'SAFKOSPINN', 'SUMITPOWER', 'SAIHAMTEX', 'STYLECRAFT', 'STANDBANKL', 'SALAMCRST', 'STANDARINS', 'STANCERAM', 'SALVOCHEM', 'SAMATALETH', 'SQURPHARMA', 'SQUARETEXT', 'FUWANGCER', 'SAMORITA', 'SANDHANINS', 'SAPORTL', 'SAVAREFR', 'SHAHJABANK', 'SHYAMPSUG', 'SIBL', 'SPCERAMICS', 'SINGERBD', 'SOUTHEASTB', 'SONARGAON', 'SINOBANGLA', 'SONARBAINS', 'SONALIANSH', 'LRGLOBMF1', 'RELIANCE1', 'MJLBD', 'ZAHINTEX', 'ABB1STMF', 'FBFIF', 'GSPFINANCE', 'GPHISPAT', 'PADMALIFE', 'NCCBLMF1', 'GBBPOWER', 'BSCCL', 'SAIHAMCOT', 'UNIQUEHRL', 'AAMRATECH', 'GENNEXT', 'ENVOYTEX', 'ARGONDENIM', 'PREMIERCEM', 'GHAIL', 'GHCL', 'ORIONPHARM', 'BENGALWTL', 'FAMILYTEX', 'JMISMDL', 'EXIM1STMF', 'CENTRALPHL', 'FAREASTFIN', 'APOLOISPAT', 'MHSML', 'AFCAGRO', 'EMERALDOIL', 'MATINSPINN', 'HWAWELLTEX', 'WATACHEM', 'PENINSULA', 'FARCHEM', 'SPCL', 'KPPL', 'FEKDIL', 'SHURWID', 'RSRMSTEEL', 'SAIFPOWER', 'WMSHIPYARD', 'KBPPWBIL', 'HFL', 'NFML', 'IFADAUTOS', 'SHASHADNIM', 'ZAHEENSPIN', 'ATCSLGF', 'UPGDCL', 'BSRMLTD', 'TOSRIFA', 'OAL', 'AMANFEED', 'KDSALTD', 'SIMTEX', 'REGENTTEX', 'ITC', 'SEMLLECMF', 'VAMLBDMF1', 'DSSL', 'DOREENPWR', 'BNICL', 'ACMELAB', 'ETL', 'YPL', 'FORTUNE', 'VAMLRBBF', 'CAPMBDBLMF', 'PDL', 'SEMLIBBLSF', 'SHEPHERD', 'NURANI', 'BBSCABLES', 'AAMRANET', 'OIMEX', 'AIL', 'NAHEEACP', 'QUEENSOUTH', 'CAPMIBBLMF', 'ADVENT', 'INTRACO', 'BPML', 'SKTRIMS', 'ACFL', 'VFSTDL', 'MLDYEING', 'SILVAPHL', 'IBP', 'KTL', 'SSSTEEL', 'GENEXIL', 'SEMLFBSLGF', 'ESQUIRENIT', 'RUNNERAUTO', 'NEWLINE', 'SILCOPHL', 'SEAPEARL', 'COPPERTECH', 'RINGSHINE', 'ADNTEL', 'SONALIPAPR', 'EIL', 'IBBLPBOND', 'WALTONHIL', 'AOL', 'UNILEVERCL', 'DOMINAGE', 'MONNOAGML', 'CRYSTALINS', 'ROBI', 'RAHIMAFOOD', 'EPGL', 'MIRAKHTER', 'EGEN', 'LRBDL', 'NRBCBANK', 'DGIC', 'INDEXAGRO', 'PAPERPROC', 'MONOSPOOL', 'MONNOFABR', 'TAMIJTEX', 'SONALILIFE', 'BPPL', 'SBACBANK', 'LOVELLO', 'SKICL', 'ACMEPL', 'AIBLPBOND', 'SJIBLPBOND', 'UNIONINS', 'BEXGSUKUK', 'BDTHAIFOOD', 'UNIONBANK', 'JHRML', 'PBLPBOND', 'MEGHNAINS', 'ACHIASF', 'APEXWEAV', 'BDPAINTS', 'BENGALBISC', 'HIMADRI', 'KBSEED', 'KFL', 'MAMUNAGRO', 'MASTERAGRO', 'MOSTFAMETL', 'NIALCO', 'ORYZAAGRO', 'SADHESIVE', 'WONDERTOYS', 'YUSUFLOUR', 'GLDNJMF', 'NAVANAPHAR', 'CLICL', 'GIB', 'ICICL']\n",
    "All_A_cat_company = ['1JANATAMF', 'PTL', '1STPRIMFMF', 'ACI', 'ACIFORMULA', 'AFTABAUTO', 'AGRANINS', 'AIBL1STIMF', 'ALARABANK', 'AMBEEPHA', 'AMCL(PRAN)', 'ANWARGALV', 'APEXFOOT', 'APEXFOODS', 'APEXSPINN', 'BEACONPHAR', 'BARKAPOWER', 'BERGERPBL', 'BEXIMCO', 'BGIC', 'APEXTANRY', 'ARAMIT', 'ASIAINS', 'ASIAPACINS', 'BANKASIA', 'LINDEBD', 'BRACBANK', 'BSC', 'BSRMSTEEL', 'BXPHARMA', 'CENTRALINS', 'CITYBANK', 'CITYGENINS', 'CONFIDCEM', 'BATASHOE', 'BATBC', 'BDCOM', 'BDFINANCE', 'BDLAMPS', 'CONTININS', 'CVOPRL', 'DBH', 'DBH1STMF', 'DELTALIFE', 'DESCO', 'DHAKABANK', 'DHAKAINS', 'DSHGARME', 'DUTCHBANGL', 'EASTERNINS', 'EASTLAND', 'EASTRNLUB', 'EBL', 'EBL1STMF', 'EBLNRBMF', 'EHL', 'EXIMBANK', 'FAREASTLIF', 'FEDERALINS', 'FIRSTSBANK', 'GEMINISEA', 'GLOBALINS', 'GP', 'GRAMEENS2', 'GREENDELMF', 'GREENDELT', 'HEIDELBCEM', 'HRTEX', 'IBNSINA', 'ICB', 'ICB3RDNRB', 'MAKSONSPIN', 'MALEKSPIN', 'MARICO', 'MBL1STMF', 'MEGHNACEM', 'MEGHNALIFE', 'MERCANBANK', 'MERCINS', 'MONNOCERA', 'MPETROLEUM', 'MTB', 'NATLIFEINS', 'NAVANACNG', 'ICBAMCL2ND', 'IDLC', 'IFIC1STMF', 'IFILISLMF1', 'IPDC', 'ISLAMIBANK', 'ISLAMICFIN', 'ISLAMIINS', 'JAMUNABANK', 'JAMUNAOIL', 'JANATAINS', 'KARNAPHULI', 'KOHINOOR', 'KPCL', 'LHBL', 'LANKABAFIN', 'NCCBANK', 'NHFIL', 'NITOLINS', 'NORTHERN', 'PRAGATIINS', 'PRAGATILIF', 'PREMIERBAN', 'PRIME1ICBA', 'PRIMEBANK', 'PRIMELIFE', 'PROGRESLIF', 'NORTHRNINS', 'NPOLYMER', 'OLYMPIC', 'ORIONINFU', 'PADMAOIL', 'PARAMOUNT', 'PEOPLESINS', 'PF1STMF', 'PHARMAID', 'PHENIXINS', 'PHOENIXFIN', 'PHPMF1', 'PIONEERINS', 'POPULAR1MF', 'POPULARLIF', 'POWERGRID',\n",
    "                     'PROVATIINS', 'PUBALIBANK', 'PURABIGEN', 'RAHIMTEXT', 'RAKCERAMIC', 'RANFOUNDRY', 'RECKITTBEN', 'RELIANCINS', 'RENATA', 'RENWICKJA', 'REPUBLIC', 'RUPALIINS', 'RUPALILIFE', 'UTTARABANK', 'UNITEDINS', 'UNITEDFIN', 'UCB', 'TRUSTBANK', 'TRUSTB1MF', 'TITASGAS', 'TAKAFULINS', 'SUMITPOWER', 'SAIHAMTEX', 'STANDARINS', 'SALVOCHEM', 'SQURPHARMA', 'SQUARETEXT', 'SAMORITA', 'SANDHANINS', 'SAPORTL', 'SHAHJABANK', 'SIBL', 'SINGERBD', 'SOUTHEASTB', 'SINOBANGLA', 'SONARBAINS', 'SONALIANSH', 'LRGLOBMF1', 'RELIANCE1', 'MJLBD', 'ABB1STMF', 'FBFIF', 'GSPFINANCE', 'GPHISPAT', 'NCCBLMF1', 'BSCCL', 'SAIHAMCOT', 'UNIQUEHRL', 'AAMRATECH', 'ENVOYTEX', 'ARGONDENIM', 'PREMIERCEM', 'ORIONPHARM', 'JMISMDL', 'EXIM1STMF', 'MATINSPINN', 'HWAWELLTEX', 'WATACHEM', 'SPCL', 'FEKDIL', 'SHURWID', 'RSRMSTEEL', 'SAIFPOWER', 'IFADAUTOS', 'SHASHADNIM', 'ATCSLGF', 'UPGDCL', 'BSRMLTD', 'AMANFEED', 'KDSALTD', 'SEMLLECMF', 'VAMLBDMF1', 'DOREENPWR', 'BNICL', 'ACMELAB', 'FORTUNE', 'VAMLRBBF', 'CAPMBDBLMF', 'SEMLIBBLSF', 'SHEPHERD', 'NURANI', 'BBSCABLES', 'AAMRANET', 'OIMEX', 'AIL', 'NAHEEACP', 'QUEENSOUTH', 'CAPMIBBLMF', 'INTRACO', 'BPML', 'ACFL', 'VFSTDL', 'MLDYEING', 'KTL', 'SSSTEEL', 'GENEXIL', 'SEMLFBSLGF', 'ESQUIRENIT', 'RUNNERAUTO', 'NEWLINE', 'SEAPEARL', 'RINGSHINE', 'ADNTEL', 'SONALIPAPR', 'EIL', 'IBBLPBOND', 'WALTONHIL', 'AOL', 'UNILEVERCL', 'MONNOAGML', 'CRYSTALINS', 'EPGL', 'MIRAKHTER', 'EGEN', 'LRBDL', 'NRBCBANK', 'DGIC', 'INDEXAGRO', 'MONOSPOOL', 'TAMIJTEX', 'SONALILIFE', 'BPPL', 'LOVELLO', 'SKICL', 'AIBLPBOND', 'BEXGSUKUK', 'JHRML', 'GLDNJMF', 'NAVANAPHAR']\n",
    "All_Pharma_company = ['ACI', 'ACIFORMULA', 'ACTIVEFINE', 'AMBEEPHA', 'BEACONPHAR', 'BXPHARMA', 'IBNSINA', 'LIBRAINFU', 'MARICO', 'IMAMBUTTON', 'KEYACOSMET', 'KOHINOOR', 'ORIONINFU', 'PHARMAID', 'RECKITTBEN', 'RENATA', 'SALVOCHEM',\n",
    "                      'SQURPHARMA', 'GHCL', 'ORIONPHARM', 'JMISMDL', 'CENTRALPHL', 'AFCAGRO', 'WATACHEM', 'FARCHEM', 'ACMELAB', 'ADVENT', 'SILVAPHL', 'IBP', 'SILCOPHL', 'ACMEPL', 'JHRML', 'BDPAINTS', 'MAMUNAGRO', 'SADHESIVE', 'NAVANAPHAR']\n",
    "All_Sector_list = [\"Bank\", \"Cement\", \"Ceramics Sector\", \"Corporate Bond\", \"Engineering\", \"Financial Institutions\", \"Food & Allied\", \"Fuel & Power\", \"Insurance\", \"IT Sector\", \"Jute\", \"Life Insurance\",\n",
    "                   \"Miscellaneous\", \"Mutual Funds\", \"Paper & Printing\", \"Pharmaceuticals & Chemicals\", \"Services & Real Estate\", \"Tannery Industries\", \"Telecommunication\", \"Textile\", \"Travel & Leisure\", ]\n",
    "month_list = ['January', 'February', 'March', 'April', 'May', 'June', 'July', \n",
    "              'August', 'September', 'October', 'November', 'December']\n",
    "year_list = ['2012','2013',\n",
    "             '2014','2015',\n",
    "             '2016','2017',\n",
    "             '2018','2019',\n",
    "             '2020','2021',\n",
    "             '2022','2023',]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### date format change\n",
    "[back to top](#table-of-content)\n",
    "\n",
    "```python\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the date\n",
    "# historical data date format is like 20120101.csv so we need to fix it\n",
    "#  every date is in this format 20210101 convet to 2021-01-01 \n",
    "\n",
    "date_list = []\n",
    "for i in daily_data:\n",
    "    date_list.append(i.strip('.csv').split(' ')[0])\n",
    "date_list = [date[:4]+'-'+date[4:6]+'-'+date[6:] for date in date_list]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sector volume \n",
    "[back to top](#table-of-content)\n",
    "\n",
    "```python\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sector = \"Pharmaceuticals & Chemicals\" vloume\n",
    "def sector_volume(sector=\"Pharmaceuticals & Chemicals\"):\n",
    "    '''\n",
    "    args: sector name \n",
    "\n",
    "    return: sector volume list \n",
    "    \n",
    "    summary: return sector volume list of sector name \n",
    "\n",
    "    '''\n",
    "    Sector_Volume2 = []\n",
    "    for i in os.listdir(daily_data_dir):\n",
    "        df = pd.read_csv(daily_data_dir+\"\\\\\"+i)\n",
    "        pharma_volume = df.loc[df['Scrip'] ==\n",
    "                            sector]['Volume'].values[0]\n",
    "        Sector_Volume2.append(pharma_volume)\n",
    "    return Sector_Volume2\n",
    "\n",
    "# create a dataframe for sector volume\n",
    "Sector_Volume2=sector_volume()\n",
    "Sector_Volume_df = pd.DataFrame(\n",
    "    {'Date': date_list, 'Sector_Volume': Sector_Volume2})\n",
    "# save the dataframe\n",
    "Sector_Volume_df.to_csv('dataset_v1_df.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all A catagory company volume\n",
    "All_A_Catagory_Volume = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df1 = pd.read_csv(new_data_dir)\n",
    "comp_name = df1['Unnamed: 0'].tolist()\n",
    "comp_type = df1['Unnamed: 2'].tolist()\n",
    "comp_sector = df1['Trade Info'].tolist()\n",
    "\n",
    "for i in range(len(comp_name)):\n",
    "    if comp_type[i].startswith('A'):\n",
    "        A_cat_comapny.append(comp_name[i])\n",
    "\n",
    "for i in range(len(comp_name)):\n",
    "    if comp_sector[i].startswith('Pharma'):\n",
    "        pharma_comapny.append(comp_name[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date format change\n",
    "daily_data = os.listdir(daily_data_dir)\n",
    "date_list = []\n",
    "for i in daily_data:\n",
    "    date_list.append(i.strip('.csv').split(' ')[0])\n",
    "date_list = [date[:4]+'-'+date[4:6]+'-'+date[6:] for date in date_list]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dses , Dsex , Ds30 \n",
    "[back to top](#table-of-content)\n",
    "\n",
    "```python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dses , dsex , ds30\n",
    "def dses_dsex_ds30(daily_data_dir=daily_data_dir):\n",
    "    '''\n",
    "    args: daily_data_dir(historica data directory)\n",
    "    return: Dses, Ds30, Dsex \n",
    "    \n",
    "    summary: return Dses, Ds30, Dsex list according to date aviablity \n",
    "    '''\n",
    "\n",
    "    Dses = []\n",
    "    Ds30 = []\n",
    "    Dsex = []\n",
    "\n",
    "    for i in os.listdir(daily_data_dir):\n",
    "        df = pd.read_csv(daily_data_dir+\"\\\\\"+i)\n",
    "        try:\n",
    "            x = df.loc[df['Scrip'] == 'DSES']['Close'].values[0]\n",
    "            Dses.append(x)\n",
    "            y = df.loc[df['Scrip'] == 'DS30']['Close'].values[0]\n",
    "            Ds30.append(y)\n",
    "            z = df.loc[df['Scrip'] == 'DSEX']['Close'].values[0]\n",
    "            Dsex.append(z)\n",
    "        except:\n",
    "            Dses.append(0)\n",
    "            Ds30.append(0)\n",
    "            Dsex.append(0)\n",
    "    return Dses, Ds30, Dsex \n",
    "\n",
    "Dses, Ds30, Dsex = dses_dsex_ds30()\n",
    "# create a dataframe for Date,Sector_Volume,dses , dsex , ds30\n",
    "df = pd.DataFrame({'Date': date_list, 'Sector_Volume': Sector_Volume2,\n",
    "                  'Dses': Dses, 'Ds30': Ds30, 'Dsex': Dsex})\n",
    "# save the dataframe\n",
    "df.to_csv(data_dir+'dataset_v2_df.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DSES , DSEX , DS30 change\n",
    " [back to top](#table-of-content)\n",
    "\n",
    "```python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dses_dsex_ds30_change(daily_data_dir=daily_data_dir):\n",
    "    '''\n",
    "    args: daily_data_dir(historica data directory)\n",
    "    return: Dses_change, Ds30_change, Dsex_change\n",
    "    \n",
    "    summary: return Dses_change, Ds30_change, Dsex_change list according to \n",
    "    date aviablity , the calculation is done by subtracting the previous day value\n",
    "    from the current day value. \n",
    "    \n",
    "    '''\n",
    "    Dses_change = [0]\n",
    "    Ds30_change = [0]\n",
    "    Dsex_change = [0]\n",
    "    for i in range(len(Dses)-1):\n",
    "        Dses_change.append(Dses[i+1]-Dses[i])\n",
    "        Ds30_change.append(Ds30[i+1]-Ds30[i])\n",
    "        Dsex_change.append(Dsex[i+1]-Dsex[i])\n",
    "    return Dses_change, Ds30_change, Dsex_change\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Dses_change, Ds30_change, Dsex_change = dses_dsex_ds30_change()\n",
    "# create a dataframe for Date,Sector_Volume,dses , dsex , ds30 , Dses_change , Ds30_change , Dsex_change\n",
    "df = pd.DataFrame({'Date': date_list, 'Sector_Volume': Sector_Volume2, 'Dses': Dses, 'Ds30': Ds30,\n",
    "                  'Dsex': Dsex, 'Dses_change': Dses_change, 'Ds30_change': Ds30_change, 'Dsex_change': Dsex_change})\n",
    "# save the dataframe\n",
    "df.to_csv(data_dir+'dataset_v3_df.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking by sector volume \n",
    "[back to top](#table-of-content)\n",
    "\n",
    "```python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ranking_by_sector_volume(daily_data_dir=daily_data_dir, sector='SQURPHARMA'):\n",
    "    '''\n",
    "    args: daily_data_dir(historica data directory)\n",
    "    return: ranking_by_sector_volume\n",
    "    \n",
    "    summary: return ranking_by_sector_volume list according to date aviablity \n",
    "    remove DSES, DS30, DSEX from the list and also remove last 21 row from the list \n",
    "    sort the list by volume and find the position of SQURPHARMA \n",
    "    \n",
    "    '''\n",
    "\n",
    "    \n",
    "    ranking_by_sector_volume = []\n",
    "    rows = [\"DSES\", \"DS30\", \"DSEX\"]\n",
    "    for i in os.listdir(daily_data_dir):\n",
    "        df = pd.read_csv(daily_data_dir+\"\\\\\"+i)\n",
    "        df = df.iloc[:-21]  # last 21 row is not a company , sector\n",
    "        try:\n",
    "            df = df[~df['Scrip'].isin(rows)]\n",
    "            sort_df = df.sort_values(\n",
    "                by=['Volume'], ascending=False).reset_index(drop=True)\n",
    "            # find SQURPHARMA position\n",
    "            index = sort_df[sort_df['Scrip'] == sector].index[0]\n",
    "       \n",
    "            \n",
    "            ranking_by_sector_volume.append(index)\n",
    "        except:\n",
    "            ranking_by_sector_volume.append(0)\n",
    "    return ranking_by_sector_volume\n",
    "\n",
    "\n",
    "\n",
    "ranking_by_sector_volume = ranking_by_sector_volume()\n",
    "# # create a dataframe for Date,Sector_Volume,dses , dsex , ds30 , Dses_change , Ds30_change , Dsex_change , ranking_by_sector_volume\n",
    "# df = pd.DataFrame({'Date': date_list, 'Sector_Volume': Sector_Volume2, 'Dses': Dses, 'Ds30': Ds30, 'Dsex': Dsex,\n",
    "#                   'Dses_change': Dses_change, 'Ds30_change': Ds30_change, 'Dsex_change': Dsex_change, 'ranking': ranking_by_sector_volume})\n",
    "# # #save the dataframe\n",
    "# df.to_csv(data_dir+'dataset_v4_df.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[102, 125, 131, 96, 108, 90, 105, 67, 70, 93]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranking_by_sector_volume[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_modified_data = pd.read_csv(\n",
    "    r'C:\\Users\\Amzad\\Desktop\\stock_prediction\\data\\modified_data_v6.csv')\n",
    "# drop ranking_by_sector_volume column\n",
    "read_modified_data.drop(['Ranking_by_sector_volume'], axis=1, inplace=True)\n",
    "read_modified_data['Ranking'] = ranking_by_sector_volume\n",
    "read_modified_data.to_csv('modified_data_(ranking_modified).csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gold price global \n",
    "[back to top](#table-of-content)\n",
    "\n",
    "```python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gold_price(gold_csv_dir=gold_csv_dir, latest_data_dir=latest_data_dir):\n",
    "\n",
    "    '''\n",
    "    args: gold_csv_dir(gold price csv file directory) ,\n",
    "      latest_data_dir(latest data directory)\n",
    "      \n",
    "    return: gold_price\n",
    "\n",
    "    summary: return gold_price list according to date aviablity \n",
    "    '''\n",
    "\n",
    "    read_data2 = pd.read_csv(gold_csv_dir\n",
    "        )\n",
    "    read_data = pd.read_csv(latest_data_dir\n",
    "       )\n",
    "    # convert to datetime\n",
    "    gold_price = []\n",
    "    read_data2['Date'] = pd.to_datetime(read_data2['Date'])\n",
    "    read_data2['Date'] = read_data2['Date'].dt.strftime('%Y-%m-%d')\n",
    "    gold_price = []\n",
    "\n",
    "    # sort by date\n",
    "    for i in read_data['Date']:\n",
    "        try:\n",
    "            gold_price.append(\n",
    "                read_data2.loc[read_data2['Date'] == i]['Close'].values[0])\n",
    "        except:\n",
    "            gold_price.append(0)\n",
    "    return gold_price\n",
    "\n",
    "\n",
    "gold_price = gold_price()\n",
    "# create a dataframe for Date,Sector_Volume,dses , dsex , ds30 , Dses_change , Ds30_change , Dsex_change , ranking_by_sector_volume , gold_price\n",
    "df = pd.DataFrame({'Date': date_list, 'Sector_Volume': Sector_Volume2, 'Dses': Dses, 'Ds30': Ds30, 'Dsex': Dsex, 'Dses_change': Dses_change,\n",
    "                  'Ds30_change': Ds30_change, 'Dsex_change': Dsex_change, 'ranking_by_sector_volume': ranking_by_sector_volume, 'gold_price': gold_price})\n",
    "# save the dataframe\n",
    "df.to_csv(data_dir+'dataset_v5_df.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rows = [\"DSES\", \"DS30\", \"DSEX\"]\n",
    "\n",
    "\n",
    "Sector_Volumes = []\n",
    "for i in os.listdir(daily_data_dir):\n",
    "    df2 = pd.read_csv(daily_data_dir+\"\\\\\"+i)\n",
    "    df3 = df2[df2['Scrip'] == 'Pharmaceuticals & Chemicals']['Volume'].values[0]\n",
    "    Sector_Volumes.append(df3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = []\n",
    "\n",
    "Category_A_Volumes = []\n",
    "for i in daily_data:\n",
    "    df2 = pd.read_csv(daily_data_dir+\"\\\\\"+i)\n",
    "    dates.append(df2['Date'][0])\n",
    "    Sector_Volumes.append(df2['Sector_Volume'][0])\n",
    "    Category_A_Volumes.append(df2['Category_A_Volume'][0])\n",
    "\n",
    "\n",
    "# new dataframe creation\n",
    "df6 = pd.DataFrame()\n",
    "df6['Date'] = dates\n",
    "df6['Sector_Volume'] = Sector_Volumes\n",
    "df6['Category_A_Volume'] = Category_A_Volumes\n",
    "df6.to_csv(daily_data_dir+\"\\\\\"+'modified_data_v1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_data = pd.read_csv(daily_data_dir+\"\\\\\"+'modified_data_v3.csv')\n",
    "read_data['Ranking_by_sector_volume'] = ranking_by_sector_volume\n",
    "read_data.to_csv(daily_data_dir+\"\\\\\"+'modified_data_v4.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gold close price\n",
    "gold_close_price = []\n",
    "\n",
    "read_data2 = pd.read_csv(\n",
    "    r'C:\\Users\\Amzad\\Desktop\\stock_prediction\\data\\gold.csv')\n",
    "read_data2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to datetime \n",
    "read_data2['Date']=pd.to_datetime(read_data2['Date'])\n",
    "read_data2['Date']=read_data2['Date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "read_data2.head()\n",
    "gold_close_price=[]\n",
    "\n",
    "\n",
    "# find missing date\n",
    "avilable_date=[]\n",
    "for i in read_data2['Date']:\n",
    "    if i  in read_data['Date'].values:\n",
    "        avilable_date.append(i) \n",
    "\n",
    "\n",
    "#collect the gold close price on avilable date \n",
    "for i in avilable_date:\n",
    "    gold_close_price.append(read_data2.loc[read_data2['Date']==i]['Close'].values[0])\n",
    "    \n",
    "# find gold close price on avilable date \n",
    "gold_close_price=[] \n",
    "for i in read_data['Date']: \n",
    "    try:\n",
    "        gold_close_price.append(read_data2.loc[read_data2['Date']==i]['Close'].values[0])\n",
    "    except:\n",
    "        #cal\n",
    "        gold_close_price.append(0)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_v4 = pd.read_csv(\n",
    "    r\"C:\\Users\\Amzad\\Desktop\\stock_prediction\\data\\modified_data_v4.csv\")\n",
    "data_v4['Gold_Close_Price'] = gold_close_price\n",
    "data_v4.to_csv(daily_data_dir+\"\\\\\"+'modified_data_v5.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Foren exchange buy sell rate\n",
    "\n",
    " [back to top](#table-of-content)\n",
    "\n",
    "```python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# foren exchange rate\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "\n",
    "url = 'https://www.bb.org.bd/en/index.php/econdata/exchangerate'\n",
    "\n",
    "def foren_exchange_rate(url=url, month_list=month_list, yaer_list=year_list):\n",
    "    '''\n",
    "    arg : url, month_list, year_list \n",
    "    return : month_date, buy, sell\n",
    "\n",
    "    sumary : scrap the foren exchange rate from the url according \n",
    "    to the month and year list \n",
    "\n",
    "    '''\n",
    "\n",
    "\n",
    "\n",
    "    month_date = []\n",
    "    buy = []\n",
    "    sell = []\n",
    "    count = 0\n",
    "    for i in yaer_list:\n",
    "        for j in month_list:\n",
    "            try:\n",
    "                if j == 'None':\n",
    "                    break\n",
    "                else:\n",
    "                    payload = {'currencies': 'usd', 'date_picker': j+', '+i}\n",
    "                    r = requests.post(url, data=payload)\n",
    "                    soup = bs(r.text, 'html.parser')\n",
    "                    table = soup.find_all('table')\n",
    "                    table_row = table[0].find_all('td')\n",
    "                    count += 1\n",
    "\n",
    "                    for k in table_row[3:]:\n",
    "                        month_date.append(k.text)\n",
    "            except:\n",
    "\n",
    "                print(count)\n",
    "\n",
    "    return month_date, buy, sell\n",
    "\n",
    "\n",
    "\n",
    "month_date, buy, sell=foren_exchange_rate(url, month_list, year_list)\n",
    "df = pd.DataFrame()\n",
    "df['Date'] = month_date\n",
    "df.to_csv(\n",
    "    r'C:\\Users\\Amzad\\Desktop\\stock_prediction\\data\\test_fe_rate.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = []\n",
    "buy = []\n",
    "sell = []\n",
    "for i in range(0, len(month_date)-3, 3):\n",
    "\n",
    "    date.append(month_date[i])\n",
    "    buy.append(month_date[i+1])\n",
    "    sell.append(month_date[i+2])\n",
    "\n",
    "\n",
    "# make a dataframe\n",
    "df = pd.DataFrame()\n",
    "df['Date'] = date\n",
    "df['Buy'] = buy\n",
    "df['Sell'] = sell\n",
    "df.to_csv(\n",
    "    r'C:\\Users\\Amzad\\Desktop\\stock_prediction\\data\\test_fe_rate.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fe_rate = pd.read_csv(\n",
    "    r'C:\\Users\\Amzad\\Desktop\\stock_prediction\\data\\test_fe_rate.csv')\n",
    "modifeid_data = pd.read_csv(\n",
    "    r'C:\\Users\\Amzad\\Desktop\\stock_prediction\\data\\modified_data_v6.csv')\n",
    "\n",
    "# convert to datetime\n",
    "test_fe_rate['Date'] = pd.to_datetime(test_fe_rate['Date'])\n",
    "test_fe_rate['Date'] = test_fe_rate['Date'].dt.strftime('%Y-%m-%d')\n",
    "fr_buy = []\n",
    "fr_sell = []\n",
    "for date in modifeid_data['Date']:\n",
    "    try:\n",
    "        fr_buy.append(\n",
    "            test_fe_rate.loc[test_fe_rate['Date'] == date]['Buy'].values[0])\n",
    "        fr_sell.append(\n",
    "            test_fe_rate.loc[test_fe_rate['Date'] == date]['Sell'].values[0])\n",
    "    except:\n",
    "        fr_buy.append(0)\n",
    "        fr_sell.append(0)\n",
    "\n",
    "modifeid_data['Foreign_exchange_Buy'] = fr_buy\n",
    "modifeid_data['Foreign_exchange_rate_Sell'] = fr_sell\n",
    "modifeid_data.to_csv(daily_data_dir+\"\\\\\"+'modified_data_v7.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5nn_close_price_avg \n",
    "[back to top](#table-of-content)\n",
    "\n",
    "```python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "path= r'C:\\Users\\Amzad\\Desktop\\stock_prediction\\components\\Stock Price Dataset - SQURPHARMA.csv'\n",
    "\n",
    "\n",
    "\n",
    "def five_nn_close_price_avg(path=path):\n",
    "    '''\n",
    "    arg : path (csv file path of desired stock)\n",
    "    return : dates_index, nn_close_price_avg\n",
    "\n",
    "    summary : sort the data by close price ,\n",
    "      increase the index by 1 and and\n",
    "      find out the average of next 5 close price\n",
    "\n",
    "    '''\n",
    "\n",
    "    read_stock_data = pd.read_csv(path)\n",
    "    # sort by close price and make a copy\n",
    "    read_stock_data = read_stock_data.sort_values(by='Close', ascending=False)\n",
    "    read_stock_data = read_stock_data.copy()\n",
    "    # store the index\n",
    "    index = read_stock_data.index\n",
    "    dates_index = read_stock_data['Date'].values\n",
    "    # add 1 to index\n",
    "    index = index+1\n",
    "\n",
    "    # for i in index take next five index and find the average\n",
    "    nn_close_price_avg = []\n",
    "\n",
    "    for i in index:\n",
    "        try:\n",
    "            nn_close_price_avg.append(read_stock_data.iloc[i:i+4]['Close'].mean())\n",
    "        except:\n",
    "            nn_close_price_avg.append(0)\n",
    "\n",
    "    return dates_index, nn_close_price_avg\n",
    "\n",
    "dates_index, nn_close_price_avgDS30 = five_nn_close_price_avg(path)\n",
    "# # make a dataframe\n",
    "# df = pd.DataFrame()\n",
    "# df['Date'] = dates_index\n",
    "# df['5nn_close_price_avg'] = nn_close_price_avg\n",
    "# df.to_csv(r'C:\\Users\\Amzad\\Desktop\\stock_prediction\\data\\test_5nn_close_price_avg.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the 5nn_close_price_avg of the stock accordingly dataset_v7 date\n",
    "dataset_v7 = pd.read_csv(\n",
    "    r'C:\\Users\\Amzad\\Desktop\\stock_prediction\\modified_data_v7.csv')\n",
    "\n",
    "\n",
    "test_5nn_close_price_avg = pd.read_csv(\n",
    "    r'C:\\Users\\Amzad\\Desktop\\stock_prediction\\data\\test_5nn_close_price_avg.csv')\n",
    "five_nn_close_price = []\n",
    "for date in dataset_v7['Date']:\n",
    "    try:\n",
    "        five_nn_close_price.append(\n",
    "            test_5nn_close_price_avg.loc[test_5nn_close_price_avg['Date'] == date]['5nn_close_price_avg'].values[0])\n",
    "    except:\n",
    "        five_nn_close_price.append(0)\n",
    "\n",
    "\n",
    "dataset_v7['5nn_close_price_avg'] = five_nn_close_price\n",
    "dataset_v7.to_csv('modified_data_v8.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BD resurve \n",
    "[back to top](#table-of-content)\n",
    "\n",
    "```python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['30 June, 2015\\n'] [' 25020.45']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pypdf import PdfReader\n",
    "import os \n",
    "\n",
    "\n",
    "path=r'C:\\Users\\Amzad\\Desktop\\stock-price-prediction(main)\\Data\\pdf'\n",
    "def fer(paths=path):\n",
    "    '''\n",
    "    arg: file path (path of all pdf report containing bd reserve) ) \n",
    "    return: date and reserve\n",
    "\n",
    "    summary : this function will read all the pdf file in the given path and \n",
    "    extract the date and reserve from the pdf file and return the date and reserve in a list\n",
    "\n",
    "    \n",
    "    '''\n",
    "\n",
    "    date=[]\n",
    "    reseve=[]\n",
    "    for i in os.listdir(paths):\n",
    "        try:\n",
    "            pdf=PdfReader(path+'\\\\'+i)\n",
    "            page = pdf.pages[0]\n",
    "            text = page.extract_text()\n",
    "            date.append(text[20:34])\n",
    "            reseve.append(text[76:85])\n",
    "        except:\n",
    "            print(i)\n",
    "\n",
    "    return date,reseve\n",
    "\n",
    "\n",
    "date,reseve = fer(path) \n",
    "print(date,reseve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final dataset\n",
    "# read the modified_data_v8.csv\n",
    "modifeid_data_v8 = pd.read_csv(\n",
    "    r'C:\\Users\\Amzad\\Desktop\\stock_prediction\\components\\modified_data_v8.csv')\n",
    "read_stock_data = pd.read_csv(\n",
    "    r'C:\\Users\\Amzad\\Desktop\\stock_prediction\\components\\Stock Price Dataset - SQURPHARMA.csv')\n",
    "final_dataset_date = read_stock_data['Date'].values\n",
    "\n",
    "# Date,DSES,DS30,DSEX,Category_A_Volume,DSES Index Changed,DS30 Index Changed,DSEX Index Changed,Ranking_by_sector_volume,Gold_Close_Price,Sector_Volume,Foreign_exchange_Buy,Foreign_exchange_rate_Sell,5nn_close_price_avg# store all the columns according to the final_dataset_date\n",
    "# store all the columns according to the final_dataset_date\n",
    "\n",
    "Date = []\n",
    "Dses = []\n",
    "Ds30 = []\n",
    "Dsex = []\n",
    "Category_A_Volume = []\n",
    "Dses_Index_Changed = []\n",
    "Ds30_Index_Changed = []\n",
    "Dsex_Index_Changed = []\n",
    "Ranking_by_sector_volume = []\n",
    "Gold_Close_Price = []\n",
    "Sector_Volume = []\n",
    "Foreign_exchange_Buy = []\n",
    "Foreign_exchange_rate_Sell = []\n",
    "nn_close_price_avg = []\n",
    "\n",
    "for date in final_dataset_date:\n",
    "    try:\n",
    "        Date.append(date)\n",
    "        Dses.append(\n",
    "            modifeid_data_v8.loc[modifeid_data_v8['Date'] == date]['DSES'].values[0])\n",
    "        Ds30.append(\n",
    "            modifeid_data_v8.loc[modifeid_data_v8['Date'] == date]['DS30'].values[0])\n",
    "        Dsex.append(\n",
    "            modifeid_data_v8.loc[modifeid_data_v8['Date'] == date]['DSEX'].values[0])\n",
    "        Category_A_Volume.append(\n",
    "            modifeid_data_v8.loc[modifeid_data_v8['Date'] == date]['Category_A_Volume'].values[0])\n",
    "        Dses_Index_Changed.append(modifeid_data_v8.loc[modifeid_data_v8['Date'] == date]['DSES Index Changed'].values[0])\n",
    "        Ds30_Index_Changed.append(\n",
    "            modifeid_data_v8.loc[modifeid_data_v8['Date'] == date]['DS30 Index Changed'].values[0])\n",
    "        Dsex_Index_Changed.append(\n",
    "            modifeid_data_v8.loc[modifeid_data_v8['Date'] == date]['DSEX Index Changed'].values[0])\n",
    "        Ranking_by_sector_volume.append(\n",
    "            modifeid_data_v8.loc[modifeid_data_v8['Date'] == date]['Ranking_by_sector_volume'].values[0])\n",
    "        Gold_Close_Price.append(\n",
    "            modifeid_data_v8.loc[modifeid_data_v8['Date'] == date]['Gold_Close_Price'].values[0])\n",
    "        Sector_Volume.append(\n",
    "            modifeid_data_v8.loc[modifeid_data_v8['Date'] == date]['Sector_Volume'].values[0])\n",
    "        Foreign_exchange_Buy.append(\n",
    "            modifeid_data_v8.loc[modifeid_data_v8['Date'] == date]['Foreign_exchange_Buy'].values[0])\n",
    "        Foreign_exchange_rate_Sell.append(\n",
    "            modifeid_data_v8.loc[modifeid_data_v8['Date'] == date]['Foreign_exchange_rate_Sell'].values[0])\n",
    "        nn_close_price_avg.append(\n",
    "            modifeid_data_v8.loc[modifeid_data_v8['Date'] == date]['5nn_close_price_avg'].values[0])\n",
    "    except:\n",
    "        Date.append(date)\n",
    "        Dses.append(0)\n",
    "        Ds30.append(0)\n",
    "        Dsex.append(0)\n",
    "        Category_A_Volume.append(0)\n",
    "        Dses_Index_Changed.append(0)\n",
    "        Ds30_Index_Changed.append(0)\n",
    "        Dsex_Index_Changed.append(0)\n",
    "        Ranking_by_sector_volume.append(0)\n",
    "        Gold_Close_Price.append(0)\n",
    "        Sector_Volume.append(0)\n",
    "        Foreign_exchange_Buy.append(0)\n",
    "        Foreign_exchange_rate_Sell.append(0)\n",
    "        nn_close_price_avg.append(0)\n",
    "\n",
    "\n",
    "# make a dataframe\n",
    "df = pd.DataFrame()\n",
    "df['Date'] = final_dataset_date  \n",
    "df['Sector_Volume'] = Sector_Volume\n",
    "df['Category_A_Volume'] = Category_A_Volume\n",
    "df['Date'] = final_dataset_date\n",
    "df['Dses'] = Dses\n",
    "df['Ds30'] = Ds30\n",
    "df['Dsex'] = Dsex\n",
    "df['Dses_Index_Changed'] = Dses_Index_Changed\n",
    "df['Ds30_Index_Changed'] = Ds30_Index_Changed\n",
    "df['Dsex_Index_Changed'] = Dsex_Index_Changed\n",
    "df['Ranking_by_sector_volume'] = Ranking_by_sector_volume\n",
    "df['Gold_Close_Price'] = Gold_Close_Price\n",
    "df['Foreign_exchange_Buy'] = Foreign_exchange_Buy\n",
    "df['Foreign_exchange_rate_Sell'] = Foreign_exchange_rate_Sell\n",
    "df['5nn_close_price_avg'] = nn_close_price_avg\n",
    "\n",
    "df.to_csv(\n",
    "    r'C:\\Users\\Amzad\\Desktop\\stock_prediction\\data\\final_dataset.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
